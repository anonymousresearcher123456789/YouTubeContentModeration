{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bfd07eb",
   "metadata": {
    "id": "exmY-abTefFW",
    "papermill": {
     "duration": 0.009005,
     "end_time": "2025-08-01T12:06:58.306859",
     "exception": false,
     "start_time": "2025-08-01T12:06:58.297854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abda8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:06:58.323320Z",
     "iopub.status.busy": "2025-08-01T12:06:58.322866Z",
     "iopub.status.idle": "2025-08-01T12:07:49.920378Z",
     "shell.execute_reply": "2025-08-01T12:07:49.918779Z"
    },
    "id": "Bi3c0wLhh-Rf",
    "outputId": "44c463e5-7c4c-45cf-daca-75620249739c",
    "papermill": {
     "duration": 51.609238,
     "end_time": "2025-08-01T12:07:49.923192",
     "exception": false,
     "start_time": "2025-08-01T12:06:58.313954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install anthropic\n",
    "!pip install ffmpeg-python\n",
    "!pip install av\n",
    "!pip install scenedetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2feead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:07:49.943688Z",
     "iopub.status.busy": "2025-08-01T12:07:49.943230Z",
     "iopub.status.idle": "2025-08-01T12:07:59.109192Z",
     "shell.execute_reply": "2025-08-01T12:07:59.107920Z"
    },
    "papermill": {
     "duration": 9.179556,
     "end_time": "2025-08-01T12:07:59.111980",
     "exception": false,
     "start_time": "2025-08-01T12:07:49.932424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from json import loads\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import ffmpeg\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import soundfile as sf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample\n",
    "import typing_extensions as typing\n",
    "from scenedetect import open_video,  VideoStreamCv2, SceneManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d39b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:07:59.132251Z",
     "iopub.status.busy": "2025-08-01T12:07:59.131599Z",
     "iopub.status.idle": "2025-08-01T12:08:00.497218Z",
     "shell.execute_reply": "2025-08-01T12:08:00.495823Z"
    },
    "id": "1ksUpR0ibKve",
    "outputId": "6880ee21-f703-4761-dfcd-842e1f8b61d9",
    "papermill": {
     "duration": 1.379367,
     "end_time": "2025-08-01T12:08:00.500699",
     "exception": false,
     "start_time": "2025-08-01T12:07:59.121332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load and filter ground truth ===\n",
    "ground_df = pd.read_csv('/kaggle/input/youtube-data/ground_labels_new.csv')\n",
    "ground_df['Primary Label'] = ground_df['Primary Label'].str.lower()\n",
    "ground_df = ground_df[ground_df['Primary Label'].isin(['appropriate', 'inappropriate'])]\n",
    "ground_df['Video Id'] = ground_df['Video Id'].astype(str).str.strip()\n",
    "\n",
    "# === Step 2: Filter based on remaining IDs ===\n",
    "remaining_ids_df = pd.read_csv('/kaggle/input/dynamic-few-shot/filtered_ground_truth.csv')\n",
    "remaining_ids_df['Video Id'] = remaining_ids_df['Video Id'].astype(str).str.lstrip(\"'\").str.strip()\n",
    "filtered_ids = remaining_ids_df['Video Id'].tolist()\n",
    "ground_df = ground_df[ground_df['Video Id'].isin(filtered_ids)]\n",
    "\n",
    "# === Step 3: Load and merge with transcriptions ===\n",
    "trans_df = pd.read_csv('/kaggle/input/youtube-data/eng-complete-transcriptions.csv')\n",
    "trans_df['Video Id'] = trans_df['Video Id'].astype(str).str.strip()\n",
    "\n",
    "# Keep only the transcription column and Video Id\n",
    "trans_df = trans_df[['Video Id', 'Transcription']]\n",
    "\n",
    "# Merge with ground truth\n",
    "merged_df = pd.merge(ground_df[['Video Id', 'Primary Label']], trans_df, on='Video Id', how='inner')\n",
    "\n",
    "# === Step 4: Load and merge with metadata ===\n",
    "meta_df = pd.read_csv('/kaggle/input/dynamic-few-shot/ad_metadata_filtered.csv')\n",
    "meta_df.rename(columns={\"id\": \"Video Id\"}, inplace=True)\n",
    "meta_df[\"Video Id\"] = meta_df[\"Video Id\"].astype(str).str.strip()\n",
    "\n",
    "# Keep only required metadata fields\n",
    "meta_df = meta_df[['Video Id', 'title', 'channelTitle', 'tags', 'description', 'thumbnail']]\n",
    "\n",
    "# Final merge\n",
    "df = pd.merge(merged_df, meta_df, on='Video Id', how='inner')\n",
    "\n",
    "# === Final check ===\n",
    "print(f\"Final merged dataframe shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493e94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.522968Z",
     "iopub.status.busy": "2025-08-01T12:08:00.522581Z",
     "iopub.status.idle": "2025-08-01T12:08:00.530044Z",
     "shell.execute_reply": "2025-08-01T12:08:00.528643Z"
    },
    "id": "oR7rNEX3rl2I",
    "papermill": {
     "duration": 0.020957,
     "end_time": "2025-08-01T12:08:00.532836",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.511879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting video ids and primary labels\n",
    "\n",
    "video_ids = list(df['Video Id'])\n",
    "primary_labels = list(df['Primary Label'])\n",
    "all_transcriptions = list(df['Transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a2529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.554593Z",
     "iopub.status.busy": "2025-08-01T12:08:00.554207Z",
     "iopub.status.idle": "2025-08-01T12:08:00.577100Z",
     "shell.execute_reply": "2025-08-01T12:08:00.575855Z"
    },
    "id": "_7p-efT9sNMf",
    "papermill": {
     "duration": 0.03692,
     "end_time": "2025-08-01T12:08:00.579727",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.542807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting data from transcripts\n",
    "\n",
    "transcriptions = []\n",
    "lengths = []\n",
    "\n",
    "for (i, id_) in enumerate(video_ids):\n",
    "    transcriptions.append(all_transcriptions[i].split(\"chunks\")[0])\n",
    "    lengths.append(len(all_transcriptions[i].split(\"chunks\")[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a97b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.601689Z",
     "iopub.status.busy": "2025-08-01T12:08:00.601260Z",
     "iopub.status.idle": "2025-08-01T12:08:00.637330Z",
     "shell.execute_reply": "2025-08-01T12:08:00.636012Z"
    },
    "papermill": {
     "duration": 0.050844,
     "end_time": "2025-08-01T12:08:00.640158",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.589314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "available_ids = os.listdir('/kaggle/input/youtube-data/Ads/Ads') \n",
    "len(available_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a28f70",
   "metadata": {
    "papermill": {
     "duration": 0.009831,
     "end_time": "2025-08-01T12:08:00.660695",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.650864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Extracting Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269e4ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.684553Z",
     "iopub.status.busy": "2025-08-01T12:08:00.683828Z",
     "iopub.status.idle": "2025-08-01T12:08:00.700173Z",
     "shell.execute_reply": "2025-08-01T12:08:00.698682Z"
    },
    "papermill": {
     "duration": 0.031687,
     "end_time": "2025-08-01T12:08:00.702968",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.671281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_scenes(video_path, threshold = 30):\n",
    "    \"\"\"Detect scenes in a video and return scene start and end frames.\"\"\"\n",
    "    scene_list = []\n",
    "    while len(scene_list) < 6 and threshold > 0:\n",
    "        threshold //= 2\n",
    "    \n",
    "        video = open_video(video_path)\n",
    "        scene_manager = SceneManager()\n",
    "        scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
    "    \n",
    "        scene_manager.detect_scenes(video)\n",
    "        scene_list = scene_manager.get_scene_list()\n",
    "    \n",
    "    return scene_list\n",
    "\n",
    "\n",
    "def get_top_n_longest_scenes(scene_list, n):\n",
    "    '''Return the top n longest scenes with start and end frame indices.'''\n",
    "    scene_durations = [(start, end - start) for start, end in scene_list]\n",
    "    scene_durations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Top n longest scenes with start and end frame indices\n",
    "    longest_scenes = [(start, start + duration) for start, duration in scene_durations[:n]]\n",
    "    return longest_scenes\n",
    "\n",
    "\n",
    "def sort_scenes_by_frame(scenes_list):\n",
    "    '''Sort scenes by their start frame number.'''\n",
    "    sorted_scenes = sorted(scenes_list, key=lambda scene: scene[0].get_frames())\n",
    "    return sorted_scenes\n",
    "\n",
    "\n",
    "def get_num_grids(video_path):\n",
    "    '''Get number of grids to be created'''\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration = total_frames / fps\n",
    "\n",
    "    # Calculate number of grids based on the duration\n",
    "    duration = round(duration, 2)\n",
    "    if ((duration // 60) + 1) <= 5:\n",
    "        return int(((duration // 60) + 1))\n",
    "    else:\n",
    "        return 5\n",
    "        \n",
    "\n",
    "def extract_k_frames_from_scene(video_path, scene, k):\n",
    "    '''Extract k frames evenly spaced from each scene.'''\n",
    "    # Extract frame numbers from scene start and end\n",
    "    start_frame = scene[0].get_frames() + 1\n",
    "    end_frame = scene[1].get_frames() - 1\n",
    "\n",
    "    # Create k equally spaced frame indices within the scene's range\n",
    "    frame_indices = np.linspace(start_frame, end_frame, k, dtype=int)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    # Extract frames from calculated indices\n",
    "    for frame_no in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def create_image_grid(frames, grid_size=(1000, 1000)):\n",
    "    '''Arrange 6 frames into a 3x2 grid and resize to the specified grid size.'''\n",
    "    # Ensure all frames have the same size for concatenation\n",
    "    frames = [cv2.resize(frame, (640, 360)) for frame in frames]  # Resize to a common size like 640x360\n",
    "    rows = [np.concatenate(frames[i:i+2], axis=1) for i in range(0, 6, 2)]\n",
    "    image_grid = np.concatenate(rows, axis=0)\n",
    "    \n",
    "    return np.array(Image.fromarray(image_grid).resize(grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4c927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.725741Z",
     "iopub.status.busy": "2025-08-01T12:08:00.725342Z",
     "iopub.status.idle": "2025-08-01T12:08:00.732684Z",
     "shell.execute_reply": "2025-08-01T12:08:00.731536Z"
    },
    "papermill": {
     "duration": 0.022029,
     "end_time": "2025-08-01T12:08:00.734983",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.712954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images(video_path, n=6):\n",
    "    ''' 1. Detect scenes\n",
    "        2. Get k; where k = num_grids\n",
    "        3. Get the 6k longest scenes\n",
    "        4. Sort scenes wrt frame numbers\n",
    "        5. Extract 1 frame per 6k scene\n",
    "        6. Create k image grids of 6 frames each\n",
    "     '''\n",
    "    scene_list = detect_scenes(video_path)\n",
    "    k = get_num_grids(video_path)\n",
    "    longest_scenes = get_top_n_longest_scenes(scene_list, n*k)\n",
    "    scenes = sort_scenes_by_frame(longest_scenes)\n",
    "\n",
    "    frames = []\n",
    "    for scene in scenes:\n",
    "        frames.extend(extract_k_frames_from_scene(video_path, scene, 1))\n",
    "\n",
    "    grids = []\n",
    "    for i in range(k):\n",
    "        start_idx = i * n\n",
    "        end_idx = start_idx + n\n",
    "        grid_frames = frames[start_idx:end_idx]\n",
    "        grid = create_image_grid(grid_frames, grid_size=(1000, 1000))\n",
    "        grids.append(grid)\n",
    "\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f84086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.756432Z",
     "iopub.status.busy": "2025-08-01T12:08:00.755975Z",
     "iopub.status.idle": "2025-08-01T12:08:00.768519Z",
     "shell.execute_reply": "2025-08-01T12:08:00.767316Z"
    },
    "papermill": {
     "duration": 0.026334,
     "end_time": "2025-08-01T12:08:00.771147",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.744813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images_2(video_path, n=6):\n",
    "    ''' \n",
    "    Extracts image grids from video based on scenes.\n",
    "    Falls back to uniform sampling if no scenes are detected.\n",
    "    '''\n",
    "    # Step 1: Detect scenes\n",
    "    scene_list = detect_scenes(video_path)\n",
    "\n",
    "    # Step 2: Get number of grids and total frames needed\n",
    "    k = get_num_grids(video_path)\n",
    "    total_frames_needed = n * k\n",
    "\n",
    "    def extract_nk_frames(video_path, total_frames_needed):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "        if total_frames == 0:\n",
    "            cap.release()\n",
    "            return []\n",
    "    \n",
    "        # Get `total_frames_needed` evenly spaced frame indices\n",
    "        selected_indices = np.linspace(0, total_frames - 1, total_frames_needed, dtype=int)\n",
    "    \n",
    "        frames = []\n",
    "        for idx in selected_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            success, frame = cap.read()\n",
    "            if success:\n",
    "                frames.append(frame)\n",
    "    \n",
    "            if len(frames) >= total_frames_needed:\n",
    "                break\n",
    "    \n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    # Case 1: No scenes detected â†’ use full video sampling\n",
    "    if not scene_list:\n",
    "        frames = extract_nk_frames(video_path, total_frames_needed)\n",
    "\n",
    "    # Case 2: Scenes detected â†’ extract from each scene\n",
    "    else:\n",
    "        available_scenes = len(scene_list)\n",
    "        frames_per_scene = total_frames_needed // available_scenes\n",
    "        remaining_frames = total_frames_needed % available_scenes\n",
    "\n",
    "        if available_scenes == 1:\n",
    "            frames_per_scene = total_frames_needed\n",
    "            remaining_frames = 0\n",
    "\n",
    "        frames = []\n",
    "        for i, scene in enumerate(scene_list):\n",
    "            num_frames = frames_per_scene + (1 if i < remaining_frames else 0)\n",
    "            frames.extend(extract_k_frames_from_scene(video_path, scene, num_frames))\n",
    "\n",
    "        frames = frames[:total_frames_needed]\n",
    "\n",
    "    # Step 3: Ensure enough frames for all grids\n",
    "    if len(frames) < n:\n",
    "        frames = frames * (n // len(frames)) + frames[:(n % len(frames))]\n",
    "\n",
    "    # Step 4: Create image grids\n",
    "    grids = []\n",
    "    for i in range(k):\n",
    "        start_idx = i * n\n",
    "        end_idx = start_idx + n\n",
    "        grid_frames = frames[start_idx:end_idx]\n",
    "        if grid_frames:\n",
    "            grid = create_image_grid(grid_frames, grid_size=(1000, 1000))\n",
    "            grids.append(grid)\n",
    "\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e49c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.794321Z",
     "iopub.status.busy": "2025-08-01T12:08:00.793834Z",
     "iopub.status.idle": "2025-08-01T12:08:00.799602Z",
     "shell.execute_reply": "2025-08-01T12:08:00.798340Z"
    },
    "papermill": {
     "duration": 0.020092,
     "end_time": "2025-08-01T12:08:00.801809",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.781717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"\" \n",
    "client = anthropic.Anthropic() \n",
    "\n",
    "len(video_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e3bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.900164Z",
     "iopub.status.busy": "2025-08-01T12:08:00.898897Z",
     "iopub.status.idle": "2025-08-01T12:08:00.906096Z",
     "shell.execute_reply": "2025-08-01T12:08:00.904433Z"
    },
    "papermill": {
     "duration": 0.020962,
     "end_time": "2025-08-01T12:08:00.908620",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.887658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    # Guess correct media type\n",
    "    media_type, _ = mimetypes.guess_type(image_path)\n",
    "    if media_type is None:\n",
    "        media_type = \"image/jpeg\"  # Default fallback\n",
    "\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        img_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    return media_type, img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993be2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.930813Z",
     "iopub.status.busy": "2025-08-01T12:08:00.930385Z",
     "iopub.status.idle": "2025-08-01T12:08:00.940902Z",
     "shell.execute_reply": "2025-08-01T12:08:00.939459Z"
    },
    "papermill": {
     "duration": 0.025702,
     "end_time": "2025-08-01T12:08:00.943840",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.918138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_video_with_images(text_input, audio_transcription, image_paths, metadata=None):\n",
    "    # === Encode all image frames ===\n",
    "    image_contents = [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": img_media_type,\n",
    "                \"data\": img_data,\n",
    "            }\n",
    "        }\n",
    "        for image_path in image_paths\n",
    "        for img_media_type, img_data in [encode_image(image_path)]\n",
    "    ]\n",
    "\n",
    "    # === Format metadata text ===\n",
    "    if metadata and isinstance(metadata, dict):\n",
    "        metadata_text = (\n",
    "            f\"Video Title: {metadata.get('title', '')}\\n\"\n",
    "            f\"Channel Title: {metadata.get('channel_title', '')}\\n\"\n",
    "            f\"Tags: {', '.join(metadata.get('tags', [])) if isinstance(metadata.get('tags'), list) else metadata.get('tags', '')}\\n\"\n",
    "            f\"Description: {metadata.get('description', '')}\"\n",
    "        )\n",
    "    else:\n",
    "        metadata_text = \"No metadata provided.\"\n",
    "\n",
    "    # === Call Claude API ===\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        system=\"You are a content classification assistant that evaluates image frames, transcriptions, and metadata to assess policy violations. Output JSON only.\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    *image_contents,\n",
    "                    {\"type\": \"text\", \"text\": f\"### METADATA\\n{metadata_text}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"### AUDIO TRANSCRIPTION\\n{audio_transcription}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"### INSTRUCTION\\n{text_input}\"}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e08769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:00.964972Z",
     "iopub.status.busy": "2025-08-01T12:08:00.964555Z",
     "iopub.status.idle": "2025-08-01T12:08:00.970730Z",
     "shell.execute_reply": "2025-08-01T12:08:00.969450Z"
    },
    "papermill": {
     "duration": 0.019498,
     "end_time": "2025-08-01T12:08:00.973119",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.953621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8e304",
   "metadata": {
    "papermill": {
     "duration": 0.010669,
     "end_time": "2025-08-01T12:08:00.994342",
     "exception": false,
     "start_time": "2025-08-01T12:08:00.983673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52388633",
   "metadata": {
    "papermill": {
     "duration": 0.009492,
     "end_time": "2025-08-01T12:08:01.014186",
     "exception": false,
     "start_time": "2025-08-01T12:08:01.004694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4113df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:01.035376Z",
     "iopub.status.busy": "2025-08-01T12:08:01.034917Z",
     "iopub.status.idle": "2025-08-01T12:08:01.045704Z",
     "shell.execute_reply": "2025-08-01T12:08:01.044462Z"
    },
    "papermill": {
     "duration": 0.024616,
     "end_time": "2025-08-01T12:08:01.048274",
     "exception": false,
     "start_time": "2025-08-01T12:08:01.023658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\"A video can be considered inappropriate for children if it contains physical violence (cartoonish, realistic, or gory), interpersonal violence (bullying, pranks, meanness, belittling, controlling behavior, talking down to others, or manipulation), self-harm or suicide (depictions of harm inflicted on oneself or suicidal thoughts/tendencies), extreme stunts (life-endangering, high-risk activities/challenges that require adult supervision), dangerous products or services (like paintball, airsoft, fireworks, weapons, hunting equipment, graffiti products), scary content (horror, suspense, loud violence, zombies, skeletons, masks, scary clowns, blood, dangerous fire, car crashes, medical procedures or other scary visuals), sexual content (innuendos, sexual behavior, nudity, suggestiveness), intimacy (romantic conduct, couples expressing love, sensual contact, dating, relationships or any expression of love or loss for a significant other,  lyrics about or mentions of love or romance, heartbreak), inappropriate clothing (significant skin exposure or sheer clothing outside of appropriate contexts such as sunbathing, swinmwear,etc), substance use (mention, depictions, or use of alcohol, drugs, tobacco), gambling (betting, gambling, casinos, online or real world casino games, online trading), offensive language (from mild to severe with words such as â€œstupidâ€ or â€œidiotâ€), stereotypes (racial, ethnic, gender, body shaming), crude humor (inappropriate humor, innuendos), weapons (guns, swords, knives, etc but toy guns such as nerf guns are fine), unsuitable media (ads for violent or adult-themed video games, casino games, games with romance or battle or first person-shooter games), fight sports (boxing, wrestling, martial arts), financial content (difference, rolling spot forex, financial spread betting and synonymous products but banking ads are fine), health and beauty services (cosmetic procedures, weight loss, tanning, piercings, tattoos, cosmetics and makeup (no matter their essential benefits) and other products related to external personal care focused on body image but ads on fashion products and essential hygiene products like sunscreen, shampoo, toothpaste, etc. are fine, however, products like sanitary care and hair removal is inappropriate), ads or sponsored content for consumable food or drink products (regardless of nutritional content), where the product is consumed by a person or shown with branding, packaging, or promotional intent are inappropriate; general content like cooking shows, recipes, or scenes where food is simply present or being eaten without promotion are acceptable, pet/animal food products and healthcare, healthcare or medical topics (reproductive health, mental health, substance abuse, eating disorders, pharmaceuticals, health insurance, any nutritional or dietary supplements), sensitive topics (politics, religion, controversial social issues, astrology, occult, paranormal, religious sermons), privacy or safety risks (services or competitions requiring personal information, social networks for strangers, spy services, or video game skin trading), or any explicit depictions or discussions of death or dying. Consider that you are an expert content moderator. Based on the image grids provided containing frames from key scenes from within the video, the video title, channel title, description, thumbnail, tags and its transcription, is the video advertisement inappropriate for children on this definition? If it is, label it as â€œinappropriate.â€ If it is not, label it as â€œappropriate.â€ Justify your conclusion. Also, mention what language is being spoken if there is any. \n",
    "Respond in **JSON format only**. Do **not** include any commentary.\n",
    "\n",
    "Return only this format (no preamble):\n",
    "\n",
    "{\n",
    "  \"label\": \"appropriate\" or \"inappropriate\",\n",
    "  \"justification\": \"brief reason\",\n",
    "  \"language\": \"language spoken in the video\"\n",
    "}\"\"\"\n",
    "\n",
    "prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a219e83",
   "metadata": {
    "id": "w8esg7q8hSTW",
    "papermill": {
     "duration": 0.010148,
     "end_time": "2025-08-01T12:08:01.069759",
     "exception": false,
     "start_time": "2025-08-01T12:08:01.059611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048da44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T12:08:01.123377Z",
     "iopub.status.busy": "2025-08-01T12:08:01.122950Z",
     "iopub.status.idle": "2025-08-01T13:37:04.354203Z",
     "shell.execute_reply": "2025-08-01T13:37:04.352632Z"
    },
    "papermill": {
     "duration": 5343.246611,
     "end_time": "2025-08-01T13:37:04.357028",
     "exception": false,
     "start_time": "2025-08-01T12:08:01.110417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# === Parameters ===\n",
    "start = 1846\n",
    "end = 2306\n",
    "TEMP_THUMB_PATH = \"/kaggle/working/temp_thumb.jpg\"\n",
    "img_dir = '/kaggle/working/Images'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "# === Output containers ===\n",
    "ids = []\n",
    "predicted_labels = []\n",
    "languages = []\n",
    "responses = []\n",
    "ground_truths_ = []\n",
    "remaining = []\n",
    "\n",
    "# === Slice metadata ===\n",
    "metadata_df = df.iloc[start:end].reset_index(drop=True)\n",
    "print(f\"Filtered metadata contains {len(metadata_df)} remaining ads.\")\n",
    "\n",
    "for i, row in metadata_df.iterrows():\n",
    "    ad_id = row[\"Video Id\"]\n",
    "    if ad_id not in available_ids:\n",
    "        continue\n",
    "\n",
    "    print(f'\\nID: {ad_id}')\n",
    "    try:\n",
    "        # === File paths ===\n",
    "        ad_path = f'/kaggle/input/youtube-data/Ads/Ads/{ad_id}'\n",
    "        contents = os.listdir(ad_path)\n",
    "        contents.remove('audio.mp3')\n",
    "        video_path = os.path.join(ad_path, contents[0])\n",
    "\n",
    "        # === Transcription ===\n",
    "        audio = row['Transcription'] if pd.notna(row.get('Transcription')) else ''\n",
    "\n",
    "        # === Extract frames ===\n",
    "        try:\n",
    "            images = get_images(video_path)\n",
    "        except:\n",
    "            images = get_images_2(video_path)\n",
    "\n",
    "        image_paths = []\n",
    "        for idx, img in enumerate(images):\n",
    "            image = Image.fromarray(img)\n",
    "            path = os.path.join(img_dir, f\"{ad_id}_{idx + 1}.png\")\n",
    "            image.save(path)\n",
    "            image_paths.append(path)\n",
    "            print(\"ðŸ–¼ Saved:\", path)\n",
    "\n",
    "        # === Metadata ===\n",
    "        title = row.get('title', '')\n",
    "        description = row.get('description', '')\n",
    "        channel_title = row.get('channelTitle', '')\n",
    "        tags = row.get('tags', '')\n",
    "        primary_label = row.get('Primary Label', '')\n",
    "\n",
    "        # === Download & save thumbnail ===\n",
    "        try:\n",
    "            r = requests.get(f\"https://i.ytimg.com/vi/{ad_id}/default.jpg\")\n",
    "            if r.status_code == 200:\n",
    "                with open(TEMP_THUMB_PATH, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                image_paths.append(TEMP_THUMB_PATH)\n",
    "                print(\"Thumbnail saved:\", TEMP_THUMB_PATH)\n",
    "            else:\n",
    "                print(\"Thumbnail download failed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Thumbnail error: {e}\")\n",
    "\n",
    "        # === JSON input for metadata ===\n",
    "        json_input = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"channel_title\": channel_title,\n",
    "            \"tags\": tags\n",
    "        }\n",
    "\n",
    "        # === Inference ===\n",
    "        print(f\"Making inference for {i}...\")\n",
    "        classification_response = classify_video_with_images(\n",
    "            prompt, audio, image_paths, json_input\n",
    "        )\n",
    "\n",
    "        raw_text = classification_response.content[0].text.strip()\n",
    "        print(f\"Raw response text: {repr(raw_text)}\")\n",
    "\n",
    "        # === Try parsing JSON ===\n",
    "        try:\n",
    "            if raw_text.startswith(\"```json\"):\n",
    "                raw_text = raw_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(raw_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing failed: {e}\")\n",
    "            json_match = re.search(r'\\{[\\s\\S]*\\}', raw_text)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    raw_text = json_match.group(0)\n",
    "                    parsed = json.loads(raw_text)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Second attempt JSON error: {e2}\")\n",
    "                    remaining.append(ad_id)\n",
    "                    continue\n",
    "            else:\n",
    "                print(\"No valid JSON found.\")\n",
    "                remaining.append(ad_id)\n",
    "                continue\n",
    "\n",
    "        # === Extract values ===\n",
    "        pred_temp = parsed.get('label') or parsed.get('classification')\n",
    "        lang_temp = parsed.get('language')\n",
    "        print(f\"Completed: {ad_id} | Label: {pred_temp} | GT: {primary_label}\")\n",
    "        print(\"Parsed Response:\", parsed)\n",
    "\n",
    "        # === Store results ===\n",
    "        ids.append(ad_id)\n",
    "        predicted_labels.append(pred_temp)\n",
    "        languages.append(lang_temp)\n",
    "        responses.append(raw_text)\n",
    "        ground_truths_.append(primary_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Failed for {ad_id}, Error: {e}')\n",
    "        remaining.append(ad_id)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "# === Final Summary ===\n",
    "print(\"\\nRemaining ads with issues:\", remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8092c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:04.612148Z",
     "iopub.status.busy": "2025-08-01T13:37:04.611646Z",
     "iopub.status.idle": "2025-08-01T13:37:04.620626Z",
     "shell.execute_reply": "2025-08-01T13:37:04.619392Z"
    },
    "papermill": {
     "duration": 0.138386,
     "end_time": "2025-08-01T13:37:04.622841",
     "exception": false,
     "start_time": "2025-08-01T13:37:04.484455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = '/kaggle/working/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3e777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:04.871930Z",
     "iopub.status.busy": "2025-08-01T13:37:04.871550Z",
     "iopub.status.idle": "2025-08-01T13:37:04.889532Z",
     "shell.execute_reply": "2025-08-01T13:37:04.887989Z"
    },
    "papermill": {
     "duration": 0.144062,
     "end_time": "2025-08-01T13:37:04.891967",
     "exception": false,
     "start_time": "2025-08-01T13:37:04.747905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# At the end, print remaining videos \n",
    "\n",
    "remaining_df = pd.DataFrame({'Video Id': remaining})\n",
    "\n",
    "# Save to CSV\n",
    "remaining_df.to_csv(f'/kaggle/working/results/DAVSP-claude-metadata-eng-remaining-{start}-{end}.csv', index=False)\n",
    "\n",
    "print(\"Remaining videos saved to remaining.csv\")\n",
    "print(\"Remaining videos with errors:\", remaining) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7783010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:05.143305Z",
     "iopub.status.busy": "2025-08-01T13:37:05.142830Z",
     "iopub.status.idle": "2025-08-01T13:37:05.162233Z",
     "shell.execute_reply": "2025-08-01T13:37:05.160786Z"
    },
    "id": "6JsiW7gbvxRA",
    "papermill": {
     "duration": 0.147236,
     "end_time": "2025-08-01T13:37:05.164520",
     "exception": false,
     "start_time": "2025-08-01T13:37:05.017284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'Video Id': ids,\n",
    "    'Primary Label': ground_truths_,\n",
    "    'Predicted Label': predicted_labels,\n",
    "    'Response': responses, \n",
    "    'Languages': languages \n",
    "})\n",
    "\n",
    "new_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef14ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:05.413897Z",
     "iopub.status.busy": "2025-08-01T13:37:05.413523Z",
     "iopub.status.idle": "2025-08-01T13:37:05.427558Z",
     "shell.execute_reply": "2025-08-01T13:37:05.426460Z"
    },
    "id": "Tv1_5sfJwRfu",
    "papermill": {
     "duration": 0.140014,
     "end_time": "2025-08-01T13:37:05.430393",
     "exception": false,
     "start_time": "2025-08-01T13:37:05.290379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(f'/kaggle/working/results/davsp_claude-metadata-eng-new-{start}-{end}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c654e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:05.675914Z",
     "iopub.status.busy": "2025-08-01T13:37:05.675513Z",
     "iopub.status.idle": "2025-08-01T13:37:05.681543Z",
     "shell.execute_reply": "2025-08-01T13:37:05.680372Z"
    },
    "id": "4hsLj8P8Mg-e",
    "papermill": {
     "duration": 0.129812,
     "end_time": "2025-08-01T13:37:05.683724",
     "exception": false,
     "start_time": "2025-08-01T13:37:05.553912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changing to binary lists \n",
    "\n",
    "predictions = [1 if pred == 'inappropriate' else 0 for pred in predicted_labels] \n",
    "ground_truths = [1 if label == 'inappropriate' else 0 for label in ground_truths_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec083b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:05.930221Z",
     "iopub.status.busy": "2025-08-01T13:37:05.929771Z",
     "iopub.status.idle": "2025-08-01T13:37:05.950812Z",
     "shell.execute_reply": "2025-08-01T13:37:05.949661Z"
    },
    "papermill": {
     "duration": 0.147539,
     "end_time": "2025-08-01T13:37:05.953298",
     "exception": false,
     "start_time": "2025-08-01T13:37:05.805759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtaining classification report \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "report = classification_report(ground_truths, predictions) \n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712c753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:37:06.201386Z",
     "iopub.status.busy": "2025-08-01T13:37:06.200953Z",
     "iopub.status.idle": "2025-08-01T13:37:06.537546Z",
     "shell.execute_reply": "2025-08-01T13:37:06.536224Z"
    },
    "papermill": {
     "duration": 0.463065,
     "end_time": "2025-08-01T13:37:06.539804",
     "exception": false,
     "start_time": "2025-08-01T13:37:06.076739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(ground_truths, predictions)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Appropriate', 'Inapproriate'], yticklabels=['Appropriate', 'Inapproriate'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5684885,
     "sourceId": 12532117,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7959558,
     "sourceId": 12601559,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7960295,
     "sourceId": 12609511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7959724,
     "sourceId": 12628253,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7945091,
     "sourceId": 12634372,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5415.074515,
   "end_time": "2025-08-01T13:37:09.730824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-01T12:06:54.656309",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
