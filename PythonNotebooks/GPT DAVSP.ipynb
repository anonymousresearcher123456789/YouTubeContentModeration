{"cells":[{"cell_type":"markdown","metadata":{"id":"exmY-abTefFW"},"source":["Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:01:43.198650Z","iopub.status.busy":"2025-07-11T13:01:43.198087Z","iopub.status.idle":"2025-07-11T13:02:31.342510Z","shell.execute_reply":"2025-07-11T13:02:31.341092Z","shell.execute_reply.started":"2025-07-11T13:01:43.198603Z"},"id":"Bi3c0wLhh-Rf","outputId":"44c463e5-7c4c-45cf-daca-75620249739c","trusted":true},"outputs":[],"source":["!pip install openai\n","!pip install ffmpeg-python\n","!pip install av\n","!pip install scenedetect"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:02:31.346110Z","iopub.status.busy":"2025-07-11T13:02:31.345540Z","iopub.status.idle":"2025-07-11T13:02:33.332541Z","shell.execute_reply":"2025-07-11T13:02:33.331284Z","shell.execute_reply.started":"2025-07-11T13:02:31.346051Z"},"id":"iNg0gXOfD_hY","trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import time\n","import json\n","import torch\n","import random\n","import ffmpeg\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from glob import glob\n","import soundfile as sf\n","from openai import OpenAI\n","from json import loads,dumps\n","import matplotlib.pyplot as plt\n","from scipy.signal import resample\n","import typing_extensions as typing\n","from google.generativeai.types import HarmCategory, HarmBlockThreshold\n","from scenedetect import open_video, VideoStreamCv2, SceneManager\n","from scenedetect.detectors import ContentDetector"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:02:33.334581Z","iopub.status.busy":"2025-07-11T13:02:33.333924Z","iopub.status.idle":"2025-07-11T13:02:33.732923Z","shell.execute_reply":"2025-07-11T13:02:33.731369Z","shell.execute_reply.started":"2025-07-11T13:02:33.334540Z"},"id":"1ksUpR0ibKve","outputId":"6880ee21-f703-4761-dfcd-842e1f8b61d9","trusted":true},"outputs":[],"source":["# Extracting all required ids \n","\n","df = pd.read_csv('/kaggle/input/youtube-data/ground_labels_new.csv') \n","\n","df['Primary Label'] = df['Primary Label'].str.lower() \n","df = df[df['Primary Label'].isin(['appropriate', 'inappropriate'])]\n","\n","transcriptions_df = pd.read_csv('/kaggle/input/youtube-data/eng-complete-transcriptions.csv')\n","df = pd.merge(df, transcriptions_df, on='Video Id', how='inner') "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:03:13.124310Z","iopub.status.busy":"2025-07-11T13:03:13.123740Z","iopub.status.idle":"2025-07-11T13:03:13.133219Z","shell.execute_reply":"2025-07-11T13:03:13.131633Z","shell.execute_reply.started":"2025-07-11T13:03:13.124267Z"},"id":"oR7rNEX3rl2I","trusted":true},"outputs":[],"source":["# Extracting video ids and primary labels\n","\n","video_ids = list(df['Video Id'])\n","primary_labels = list(df['Primary Label'])\n","all_transcriptions = list(df['Transcription'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:03:13.371621Z","iopub.status.busy":"2025-07-11T13:03:13.369954Z","iopub.status.idle":"2025-07-11T13:03:13.380162Z","shell.execute_reply":"2025-07-11T13:03:13.378511Z","shell.execute_reply.started":"2025-07-11T13:03:13.371555Z"},"trusted":true},"outputs":[],"source":["len(video_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:03:15.874528Z","iopub.status.busy":"2025-07-11T13:03:15.873970Z","iopub.status.idle":"2025-07-11T13:03:15.906536Z","shell.execute_reply":"2025-07-11T13:03:15.904781Z","shell.execute_reply.started":"2025-07-11T13:03:15.874481Z"},"id":"_7p-efT9sNMf","trusted":true},"outputs":[],"source":["# Extracting data from transcripts\n","\n","transcriptions = []\n","lengths = []\n","\n","for (i, id_) in enumerate(video_ids):\n","    transcriptions.append(all_transcriptions[i].split(\"chunks\")[0])\n","    lengths.append(len(all_transcriptions[i].split(\"chunks\")[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:03:17.533099Z","iopub.status.busy":"2025-07-11T13:03:17.532403Z","iopub.status.idle":"2025-07-11T13:03:17.550841Z","shell.execute_reply":"2025-07-11T13:03:17.548155Z","shell.execute_reply.started":"2025-07-11T13:03:17.533031Z"},"trusted":true},"outputs":[],"source":["import os \n","\n","available_ad_ids = os.listdir('/kaggle/input/youtube-data/Ads/Ads') \n","len(available_ad_ids) "]},{"cell_type":"markdown","metadata":{"id":"MyTbSTVcehXl"},"source":["**Defining Model** "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:03:54.969456Z","iopub.status.busy":"2025-07-11T13:03:54.968956Z","iopub.status.idle":"2025-07-11T13:03:54.976058Z","shell.execute_reply":"2025-07-11T13:03:54.974177Z","shell.execute_reply.started":"2025-07-11T13:03:54.969413Z"},"id":"d4BaWth9kkKa","trusted":true},"outputs":[],"source":["apikey = \"\"\n","\n","client = OpenAI(api_key=apikey) "]},{"cell_type":"markdown","metadata":{"id":"V2kv113nelLF"},"source":["**Prompt** "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:04:18.186116Z","iopub.status.busy":"2025-07-11T13:04:18.185624Z","iopub.status.idle":"2025-07-11T13:04:18.196257Z","shell.execute_reply":"2025-07-11T13:04:18.195053Z","shell.execute_reply.started":"2025-07-11T13:04:18.186076Z"},"id":"3UX0f8bHemQW","trusted":true},"outputs":[],"source":["prompt =  \"\"\"\"A video can be considered inappropriate for children if it contains physical violence (cartoonish, realistic, or gory), interpersonal violence (bullying, pranks, meanness, belittling, controlling behavior, talking down to others, or manipulation), self-harm or suicide (depictions of harm inflicted on oneself or suicidal thoughts/tendencies), extreme stunts (life-endangering, high-risk activities/challenges that require adult supervision), dangerous products or services (like paintball, airsoft, fireworks, weapons, hunting equipment, graffiti products), scary content (horror, suspense, loud violence, zombies, skeletons, masks, scary clowns, blood, dangerous fire, car crashes, medical procedures or other scary visuals), sexual content (innuendos, sexual behavior, nudity, suggestiveness), intimacy (romantic conduct, couples expressing love, sensual contact, dating, relationships or any expression of love or loss for a significant other,  lyrics about or mentions of love or romance, heartbreak), inappropriate clothing (significant skin exposure or sheer clothing outside of appropriate contexts such as sunbathing, swinmwear,etc), substance use (mention, depictions, or use of alcohol, drugs, tobacco), gambling (betting, gambling, casinos, online or real world casino games, online trading), offensive language (from mild to severe with words such as “stupid” or “idiot”), stereotypes (racial, ethnic, gender, body shaming), crude humor (inappropriate humor, innuendos), weapons (guns, swords, knives, etc but toy guns such as nerf guns are fine), unsuitable media (ads for violent or adult-themed video games, casino games, games with romance or battle or first person-shooter games), fight sports (boxing, wrestling, martial arts), financial content (difference, rolling spot forex, financial spread betting and synonymous products but banking ads are fine), health and beauty services (cosmetic procedures, weight loss, tanning, piercings, tattoos, cosmetics and makeup (no matter their essential benefits) and other products related to external personal care focused on body image but ads on fashion products and essential hygiene products like sunscreen, shampoo, toothpaste, etc. are fine, however, products like sanitary care and hair removal is inappropriate), ads or sponsored content for consumable food or drink products (regardless of nutritional content), where the product is consumed by a person or shown with branding, packaging, or promotional intent are inappropriate; general content like cooking shows, recipes, or scenes where food is simply present or being eaten without promotion are acceptable, pet/animal food products and healthcare, healthcare or medical topics (reproductive health, mental health, substance abuse, eating disorders, pharmaceuticals, health insurance, any nutritional or dietary supplements), sensitive topics (politics, religion, controversial social issues, astrology, occult, paranormal, religious sermons), privacy or safety risks (services or competitions requiring personal information, social networks for strangers, spy services, or video game skin trading), or any explicit depictions or discussions of death or dying. Consider that you are an expert content moderator. Based on the image grids provided containing frames from key scenes from within the video, is the video advertisement inappropriate for children on this definition? If it is, label it as “inappropriate.” If it is not, label it as “appropriate.” Justify your conclusion. Also, mention what language is being spoken if there is any. \n","Make the outputs in JSON format: {“label”: “appropriate” or “inappropriate”, “justification”: “brief explanation of the classification”, “language”: “language detected in the video”}.\"\"\"\n","\n","prompt "]},{"cell_type":"markdown","metadata":{},"source":["**Output Schema** "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:07:46.932755Z","iopub.status.busy":"2025-07-11T13:07:46.932221Z","iopub.status.idle":"2025-07-11T13:07:46.940416Z","shell.execute_reply":"2025-07-11T13:07:46.938609Z","shell.execute_reply.started":"2025-07-11T13:07:46.932706Z"},"trusted":true},"outputs":[],"source":["output_schema = {\n","  \"type\": \"object\",\n","  \"properties\": {\n","    \"label\": {\n","      \"type\": \"string\",\n","      \"enum\": [\"inappropriate\", \"appropriate\"]\n","    },\n","    \"justification\": {\n","      \"type\": \"string\",\n","      \"minLength\": 10\n","    }, \n","    \"languages\": {\n","        \"type\": \"array\", \n","        \"items\": {\n","            \"type\": \"string\" \n","        }\n","        \n","    }\n","  },\n","  \"required\": [\"label\", \"justification\", \"languages\"]\n","} "]},{"cell_type":"markdown","metadata":{},"source":["**Setting Up Image Data** "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:07:50.779264Z","iopub.status.busy":"2025-07-11T13:07:50.778699Z","iopub.status.idle":"2025-07-11T13:07:50.790470Z","shell.execute_reply":"2025-07-11T13:07:50.788460Z","shell.execute_reply.started":"2025-07-11T13:07:50.779185Z"},"trusted":true},"outputs":[],"source":["import base64\n","import requests\n","\n","def encode_image(image_path):\n","    \"\"\"\n","    Encodes an image at the given path to a base64 string.\n","    \"\"\"\n","    with open(image_path, \"rb\") as image_file:\n","        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n","\n","def classify_video_with_images(text_input, audio_transcription, image_paths):\n","    \"\"\"\n","    Sends text, audio transcription, and multiple images to the API for classification.\n","    \n","    Parameters:\n","    - text_input: str, the input text.\n","    - audio_transcription: str, transcription of the audio.\n","    - image_paths: list of str, paths to the images.\n","\n","    Returns:\n","    - response: The API response.\n","    \"\"\"\n","    # Encode all images to base64\n","    encoded_images = [\n","        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encode_image(path)}\"}}\n","        for path in image_paths\n","    ]\n","\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"Authorization\": f\"Bearer {apikey}\"\n","    }\n","\n","    payload = {\n","        \"model\": \"gpt-4o-2024-08-06\",\n","        \"messages\": [\n","            {\n","                \"role\": \"user\",\n","                \"content\": [\n","                    {\"type\": \"text\", \"text\": text_input},\n","                    {\"type\": \"text\", \"text\": 'Audio transcription: ' + audio_transcription},\n","                ] + encoded_images  # Append all encoded images to the message content\n","            }\n","        ],\n","        \"response_format\": {\n","            \"type\": \"json_schema\",\n","            \"json_schema\": {\n","                \"name\": \"output_schema\",\n","                \"schema\": output_schema\n","            }\n","        },\n","        \"max_tokens\": 300, \n","        \"temperature\": 0.0\n","    }\n","\n","    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n","\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:10:39.078631Z","iopub.status.busy":"2025-07-11T13:10:39.077591Z","iopub.status.idle":"2025-07-11T13:10:39.096435Z","shell.execute_reply":"2025-07-11T13:10:39.095131Z","shell.execute_reply.started":"2025-07-11T13:10:39.078581Z"},"trusted":true},"outputs":[],"source":["def detect_scenes(video_path, threshold = 30):\n","    \"\"\"Detect scenes in a video and return scene start and end frames.\"\"\"\n","    scene_list = []\n","    while len(scene_list) < 6 and threshold > 0:\n","        threshold //= 2\n","    \n","        video = open_video(video_path)\n","        scene_manager = SceneManager()\n","        scene_manager.add_detector(ContentDetector(threshold=threshold))\n","    \n","        scene_manager.detect_scenes(video)\n","        scene_list = scene_manager.get_scene_list()\n","    \n","    return scene_list\n","\n","\n","def get_top_n_longest_scenes(scene_list, n):\n","    '''Return the top n longest scenes with start and end frame indices.'''\n","    scene_durations = [(start, end - start) for start, end in scene_list]\n","    scene_durations.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Top n longest scenes with start and end frame indices\n","    longest_scenes = [(start, start + duration) for start, duration in scene_durations[:n]]\n","    return longest_scenes\n","\n","\n","def sort_scenes_by_frame(scenes_list):\n","    '''Sort scenes by their start frame number.'''\n","    sorted_scenes = sorted(scenes_list, key=lambda scene: scene[0].get_frames())\n","    return sorted_scenes\n","\n","\n","def get_num_grids(video_path):\n","    '''Get number of grids to be created'''\n","    cap = cv2.VideoCapture(video_path)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","    duration = total_frames / fps\n","\n","    # Calculate number of grids based on the duration\n","    duration = round(duration, 2)\n","    if ((duration // 60) + 1) <= 5:\n","        return int(((duration // 60) + 1))\n","    else:\n","        return 5\n","        \n","\n","def extract_k_frames_from_scene(video_path, scene, k):\n","    '''Extract k frames evenly spaced from each scene.'''\n","    # Extract frame numbers from scene start and end\n","    start_frame = scene[0].get_frames() + 1\n","    end_frame = scene[1].get_frames() - 1\n","\n","    # Create k equally spaced frame indices within the scene's range\n","    frame_indices = np.linspace(start_frame, end_frame, k, dtype=int)\n","    \n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","\n","    # Extract frames from calculated indices\n","    for frame_no in frame_indices:\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n","        ret, frame = cap.read()\n","        if ret:\n","            frames.append(frame)\n","    \n","    cap.release()\n","    return frames\n","\n","\n","def create_image_grid(frames, grid_size=(1000, 1000)):\n","    '''Arrange 6 frames into a 3x2 grid and resize to the specified grid size.'''\n","    # Ensure all frames have the same size for concatenation\n","    frames = [cv2.resize(frame, (640, 360)) for frame in frames]  # Resize to a common size like 640x360\n","    rows = [np.concatenate(frames[i:i+2], axis=1) for i in range(0, 6, 2)]\n","    image_grid = np.concatenate(rows, axis=0)\n","    \n","    return np.array(Image.fromarray(image_grid).resize(grid_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:10:39.257795Z","iopub.status.busy":"2025-07-11T13:10:39.257248Z","iopub.status.idle":"2025-07-11T13:10:39.267172Z","shell.execute_reply":"2025-07-11T13:10:39.265692Z","shell.execute_reply.started":"2025-07-11T13:10:39.257744Z"},"trusted":true},"outputs":[],"source":["def get_images(video_path, n=6):\n","    ''' 1. Detect scenes\n","        2. Get k; where k = num_grids\n","        3. Get the 6k longest scenes\n","        4. Sort scenes wrt frame numbers\n","        5. Extract 1 frame per 6k scene\n","        6. Create k image grids of 6 frames each\n","     '''\n","    scene_list = detect_scenes(video_path)\n","    k = get_num_grids(video_path)\n","    longest_scenes = get_top_n_longest_scenes(scene_list, n*k)\n","    scenes = sort_scenes_by_frame(longest_scenes)\n","\n","    frames = []\n","    for scene in scenes:\n","        frames.extend(extract_k_frames_from_scene(video_path, scene, 1))\n","\n","    grids = []\n","    for i in range(k):\n","        start_idx = i * n\n","        end_idx = start_idx + n\n","        grid_frames = frames[start_idx:end_idx]\n","        grid = create_image_grid(grid_frames, grid_size=(1000, 1000))\n","        grids.append(grid)\n","\n","    return grids"]},{"cell_type":"markdown","metadata":{"id":"w8esg7q8hSTW"},"source":["**Running Model** "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:10:51.581571Z","iopub.status.busy":"2025-07-11T13:10:51.580330Z","iopub.status.idle":"2025-07-11T13:11:33.902869Z","shell.execute_reply":"2025-07-11T13:11:33.901740Z","shell.execute_reply.started":"2025-07-11T13:10:51.581518Z"},"id":"fAc-89lDDknS","outputId":"df6ab726-c98f-4d74-b330-5dcbd5eadf36","trusted":true},"outputs":[],"source":["ids = []\n","labels = []\n","responses = []\n","predicted_labels = [] \n","languages = [] \n","remaining = [] \n","\n","img_dir = '/kaggle/working/Images'\n","if not os.path.exists(img_dir):\n","    os.makedirs(img_dir)\n","\n","for i in range(0,len(video_ids)):\n","\n","    if video_ids[i] in available_ad_ids:\n","\n","        contents_of_ad = os.listdir('/kaggle/input/youtube-data/Ads/Ads/' + video_ids[i]) \n","        contents_of_ad.remove('audio.mp3') \n","        video_path = '/kaggle/input/youtube-data/Ads/Ads/' + video_ids[i] + '/' + contents_of_ad[0] \n","\n","        print('\\n', i, video_path)\n","        \n","        try:\n","            # Extract multiple images representative of the video\n","            images = get_images(video_path)\n","\n","            # Save each image returned by extract_images_of_frames\n","            image_paths = []\n","            for idx, img in enumerate(images):\n","                # Convert NumPy array to PIL image\n","                image = Image.fromarray(img)\n","                \n","                # Save the image to a file\n","                image_name = f\"{video_ids[i]}_{idx + 1}.png\"\n","                image_path = os.path.join(img_dir, image_name)\n","                image.save(image_path)\n","                image_paths.append(image_path)\n","                \n","            # Display the images\n","            fig, axes = plt.subplots(1, len(images), figsize=(10, 3))\n","            if len(images) == 1:\n","                axes.imshow(images[0])\n","                axes.axis('off')\n","            else:\n","                for ax, img in zip(axes, images):\n","                    ax.imshow(img)\n","                    ax.axis('off')\n","\n","            plt.tight_layout()\n","            plt.show()\n","\n","            audio_transcription = transcriptions[i] \n","\n","            try: \n","                \n","                classification_response = classify_video_with_images(prompt, audio_transcription, image_paths)\n","            \n","                temp_id = video_ids[i] \n","                temp_label = primary_labels[i] \n","                temp_predicted_label = json.loads(classification_response.json()['choices'][0]['message']['content']).get('label') \n","                temp_response = classification_response.json()['choices'][0]['message']['content'] \n","                temp_languages = json.loads(classification_response.json()['choices'][0]['message']['content']).get('languages') \n","\n","                ids.append(temp_id)\n","                labels.append(temp_label)\n","                predicted_labels.append(temp_predicted_label)\n","                responses.append(temp_response)\n","                languages.append(temp_languages) \n","\n","                print('\\nPrimary Label:', primary_labels[i], '. Response:', classification_response.json()['choices'][0]['message']['content'])\n","\n","            except Exception as e: \n","                print('\\nClassification failed for ', i, 'Error:', str(e)) \n","                remaining.append(video_ids[i])\n","\n","        except Exception as e:\n","            print('\\nImage extraction failed for ', i, 'Error:', str(e))\n","            remaining.append(video_ids[i])\n","\n","        time.sleep(20) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:11:33.905693Z","iopub.status.busy":"2025-07-11T13:11:33.905224Z","iopub.status.idle":"2025-07-11T13:11:33.911369Z","shell.execute_reply":"2025-07-11T13:11:33.910063Z","shell.execute_reply.started":"2025-07-11T13:11:33.905648Z"},"trusted":true},"outputs":[],"source":["results_dir = '/kaggle/working/results'\n","if not os.path.exists(results_dir):\n","    os.makedirs(results_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:11:33.913087Z","iopub.status.busy":"2025-07-11T13:11:33.912713Z","iopub.status.idle":"2025-07-11T13:11:33.928055Z","shell.execute_reply":"2025-07-11T13:11:33.926801Z","shell.execute_reply.started":"2025-07-11T13:11:33.913052Z"},"trusted":true},"outputs":[],"source":["# At the end, print remaining videos \n","\n","remaining_df = pd.DataFrame({'Video Id': remaining})\n","\n","# Save to CSV\n","remaining_df.to_csv('/kaggle/working/results/gpt-remaining-2000-2423.csv', index=False)\n","\n","print(\"Remaining videos saved to remaining.csv\")\n","print(\"Remaining videos with errors:\", remaining) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:11:49.617814Z","iopub.status.busy":"2025-07-11T13:11:49.617283Z","iopub.status.idle":"2025-07-11T13:11:49.634341Z","shell.execute_reply":"2025-07-11T13:11:49.632993Z","shell.execute_reply.started":"2025-07-11T13:11:49.617763Z"},"id":"6JsiW7gbvxRA","trusted":true},"outputs":[],"source":["new_df = pd.DataFrame({\n","    'Video Id': ids,\n","    'Primary Label': labels,\n","    'Predicted Label': predicted_labels,\n","    'Languages': languages, \n","    'Response': responses\n","})\n","\n","new_df.head() "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:12:18.528429Z","iopub.status.busy":"2025-07-11T13:12:18.526517Z","iopub.status.idle":"2025-07-11T13:12:18.535559Z","shell.execute_reply":"2025-07-11T13:12:18.534355Z","shell.execute_reply.started":"2025-07-11T13:12:18.528376Z"},"id":"Tv1_5sfJwRfu","trusted":true},"outputs":[],"source":["new_df.to_csv('/kaggle/working/results/gpt-4o-2000-2423.csv', index=False) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:15:30.830455Z","iopub.status.busy":"2025-07-11T13:15:30.829863Z","iopub.status.idle":"2025-07-11T13:15:30.837091Z","shell.execute_reply":"2025-07-11T13:15:30.835619Z","shell.execute_reply.started":"2025-07-11T13:15:30.830407Z"},"id":"4hsLj8P8Mg-e","trusted":true},"outputs":[],"source":["# Changing to binary lists \n","\n","predictions = [1 if pred == 'inappropriate' else 0 for pred in predicted_labels] \n","ground_truths = [1 if label == 'inappropriate' else 0 for label in labels] "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:12:21.032627Z","iopub.status.busy":"2025-07-11T13:12:21.032128Z","iopub.status.idle":"2025-07-11T13:12:21.049299Z","shell.execute_reply":"2025-07-11T13:12:21.047851Z","shell.execute_reply.started":"2025-07-11T13:12:21.032579Z"},"trusted":true},"outputs":[],"source":["# Obtaining classification report \n","from sklearn.metrics import classification_report \n","\n","report = classification_report(ground_truths, predictions) \n","print(report) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-11T13:21:27.102651Z","iopub.status.busy":"2025-07-11T13:21:27.102100Z","iopub.status.idle":"2025-07-11T13:21:27.345309Z","shell.execute_reply":"2025-07-11T13:21:27.343701Z","shell.execute_reply.started":"2025-07-11T13:21:27.102605Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Explicitly set label order: 0 = Appropriate, 1 = Inappropriate\n","cm = confusion_matrix(ground_truths, predictions, labels=[0, 1])\n","\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Appropriate', 'Inappropriate'], yticklabels=['Appropriate', 'Inappropriate'])\n","\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5684885,"sourceId":12532117,"sourceType":"datasetVersion"},{"datasetId":7959558,"sourceId":12601559,"sourceType":"datasetVersion"},{"datasetId":7960295,"sourceId":12609511,"sourceType":"datasetVersion"},{"datasetId":7959724,"sourceId":12628253,"sourceType":"datasetVersion"},{"datasetId":7945091,"sourceId":12634372,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
